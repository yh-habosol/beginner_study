{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "정확도는 실제 데이터에서 예측 데이터가 얼마나 같은지를 판단하는 지표입니다. \n",
    "Accuracy = 예측 결과가 동일한 데이터 건수 / 전체 예측 데이터 건수 입니다.\n",
    "여기서 중요한 것은 정확도는 불균형한 레이블 값 분포에서 모델의 성능을 판단할 경우, 적절한 평가 지표가 아닙니다.\n",
    "예를들면 코드로 확인하겠지만, 타이타닉 데이터에서 전체 생존률과, 단순히 데이터의 성별이 여성일 경우를 비교해보면\n",
    "그 값이 비슷하게 나옵니다. 이처럼 데이터 분포도가 균일하지 않은 경우, 높은 수치가 나타날 수 있는 것이 정확도 평가 지표의 맹점입니다.\n",
    "이를 코드로 직접 확인해 보도록 하겠습니다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "##null 처리 함수\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(), inplace = True)\n",
    "    df['Cabin'].fillna('N', inplace = True)\n",
    "    df['Embarked'].fillna('N', inplace = True)\n",
    "    df['Fare'].fillna(0, inplace = True)\n",
    "    return df\n",
    "\n",
    "##불필요한 속성 제거\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId', 'Name', 'Ticket'], axis = 1, inplace = True)\n",
    "    return df\n",
    "\n",
    "##레이블 인코딩 수행\n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "#전처리 함수들 호출\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "##BaseEstimator를 상속받으면 Customized형태의 Estimator를 만들 수 있습니다.\n",
    "\n",
    "class MyDummyClassifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        pred = np.zeros((X.shape[0], 1))\n",
    "        for i in range(X.shape[0]):\n",
    "            if X['Sex'].iloc[i] == 1:\n",
    "                pred[i]=0\n",
    "            else:\n",
    "                pred[i] = 1\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7877094972067039\n"
     ]
    }
   ],
   "source": [
    "titanic_df = pd.read_csv(\"./titanic_train.csv\")\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df = titanic_df.drop('Survived', axis = 1)\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size = 0.2, random_state = 0)\n",
    "\n",
    "myclf = MyDummyClassifier()\n",
    "myclf.fit(X_train, y_train)\n",
    "pred = myclf.predict(X_test)\n",
    "print(accuracy_score(pred, y_test))\n",
    "##아래 결과를 보시면 데이터를 통해서 분석한 생존률과, 단순히 성별이 여성일때를 생존이라고 취급하고 생존률을 구했을때와\n",
    "##값이 비슷한 것을 알 수 있습니다. 따라서 이러한 결과가 나오지 않기 위해 정확도 척도를 사용할 때에는 주의가 필요합니다.\n",
    "##이러한 단점을 보완하기 위해 우선 오차 행렬에 대해 살펴보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "오차행렬은 학습된 분류 모델이 예측을 수행하면서 얼마나 헷갈려하는지를 함께 보여주는 지표입니다.\n",
    "즉, 이진 분류의 예츠 오류가 얼마인지와 더불어 어떠한 유형의 예측 오류가 발생하고 있는지를 함께 나타내는 지표입니다.\n",
    "오차행렬의 형식은 다음과 같습니다.\n",
    "            N(0)   P(1)\n",
    "     N(0)   TN     FP\n",
    "     P(1)   FN     TP\n",
    "TN은 예측을 N으로 예측했는데 실제 값도 N이라는 뜻입니다. 여기서 정확도는 전체 경우에서 예측이 맞은 경우이므로,\n",
    "accuracy = (TN + TP)/(TN + TP + FP + FN) 입니다.\n",
    "사이킷런에서 오차 행렬을 구하기 위해 confusion_matirx()라는 함수를 제공합니다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[92, 18],\n",
       "       [20, 49]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "정밀도는 예측을 Positive로 한 대상 중 예측과 실제 값이 Positive로 일치한 데이터의 비율입니다.\n",
    "재현율은 실제 값이 positive인 대상 중에서 예측과 실제 값이 Positive로 일치한 데이터의 비율입니다.\n",
    "정밀도 = TP/(TP + FP)\n",
    "재현율 = TP/(FN + TP)\n",
    "\n",
    "실제 Positive 양성인 데이터 예측을 Negative로 잘못 판단하게되면 업무상 큰 영향이 발생하는 경우 재현율이 더 중요한 지표입니다.\n",
    "실제 Negative 음성인 데이터 예측을 Positive로 잘못 판단하게되면 업무상 큰 영향이 발생하는 경우 정밀도이 더 중요한 지표입니다.\n",
    "\n",
    "타이타닉 데이터를 오차 행렬 및 정밀도, 재현율을 모두 고려하여 예측 성능을 평가해 보겠습니다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "##오차행렬, 정확도, 정밀도, 재현율 등을 한번에 호출하는 함수\n",
    "def get_clf_eval(y_test, pred):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    print(\"오차행렬\")\n",
    "    print(confusion)\n",
    "    print(\"정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}\".format(accuracy, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도: 0.8492, 정밀도: 0.7742, 재현율: 0.7869\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "titainc_df = pd.read_csv(\"./titanic_train.csv\")\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df = titanic_df.drop(\"Survived\", axis = 1)\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X_titanic_df, y_titanic_df, test_size = 0.2, random_state = 11)\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "lr_clf.fit(X_train, y_train)\n",
    "pred = lr_clf.predict(X_test)\n",
    "get_clf_eval(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(179, 2)\n",
      "[[0.4616653  0.5383347 ]\n",
      " [0.87862763 0.12137237]\n",
      " [0.87727002 0.12272998]]\n",
      "\n",
      "\n",
      "[[0.4616653  0.5383347  1.        ]\n",
      " [0.87862763 0.12137237 0.        ]\n",
      " [0.87727002 0.12272998 0.        ]]\n",
      "\n",
      "\n",
      "[1 0 0]\n"
     ]
    }
   ],
   "source": [
    "##정밀도와 재현율을 높일 수 있는 방법에 대해 알아보겠습니다.\n",
    "##정밀도와 재현율은 상호 보완적인 평가 지표입니다. 따라서 한쪽을 강제로 높이면 다른 한쪽의 수치는 떨어집니다.\n",
    "##이를 정밀도/재현율 트레이드오프라고 합니다.\n",
    "#이를 이해하기 전에 predict매소드를 자세히 살펴보도록하겠습니다.\n",
    "\n",
    "##predict는 우선 예측 데이터가 어느 레이블에 속하는지 알기 위해 개별 레이블별로 결정확률을 구합니다.\n",
    "##그 후 임계값 이상의 확률을 갖는 레이블로 최족 예측하게 되는 것입니다.\n",
    "\n",
    "pred_proba = lr_clf.predict_proba(X_test)\n",
    "pred = lr_clf.predict(X_test)\n",
    "print(pred_proba.shape)\n",
    "print(pred_proba[:3])\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "pred_proba_result = np.concatenate([pred_proba, pred.reshape(-1,1)], axis = 1)\n",
    "print(pred_proba_result[:3])\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(pred[:3])\n",
    "\n",
    "##predict는 predict_proba메서드에 기반해서 생성된 API입니다. predict는 predict_proba의 두번쨰 칼럼의 결과를 이용한 것입니다.\n",
    "##이를 이해하는 것이 사이킷런이 어떻게 트레이드오프를 구현했는지를 이해하는데 도움을 줍니다.\n",
    "##임계값을 조정함으로써 정밀도와 재현율의 성능 수치를 상호 보완적으로 조정할 수 있습니다. \n",
    "##이러한 로직을 직접 구현해 보면서 재현율/정밀도 트레이드오프를 이해해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##이를 위해 Binarizer클래스 사용법을 알아보겠습니다.\n",
    "##이 클래스는 넘파이 어레이를 treshold를 기준으로 이하는0, 초과는 1로 바꿔줍니다.\n",
    "\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "X = [[1,-1,2],[2,0,0],[0,1.1,1.2]]\n",
    "binarizer = Binarizer(threshold=1.1)\n",
    "binarizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도: 0.8492, 정밀도: 0.7742, 재현율: 0.7869\n"
     ]
    }
   ],
   "source": [
    "##이 클래스를 이용하여 predict의 의사 코드를 작성해보겠습니다.\n",
    "custom_threshold = 0.5\n",
    "\n",
    "pred_proba_1 = pred_proba[:, 1].reshape(-1,1)\n",
    "\n",
    "binarizer = Binarizer(threshold = custom_threshold).fit(pred_proba_1)\n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_test, custom_predict)\n",
    "##결과를 보시면 위에서 작성한 predict를 이용한 결과와 똑같은 것을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬\n",
      "[[99 19]\n",
      " [10 51]]\n",
      "정확도: 0.8380, 정밀도: 0.7286, 재현율: 0.8361\n"
     ]
    }
   ],
   "source": [
    "##임계값을 0.4로 해보겠습니다.\n",
    "\n",
    "custom_threshold = 0.4\n",
    "\n",
    "pred_proba_1 = pred_proba[:, 1].reshape(-1,1)\n",
    "\n",
    "binarizer = Binarizer(threshold = custom_threshold).fit(pred_proba_1)\n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_test, custom_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "##재현율을 증가했지만 정확도와 정밀도는 떨어진 것을 확인할 수 있습니다.\n",
    "##이는 참이라고 판별하는 기준을 완화하면서, Positive로 예측할 확률이 올라가게됩니다.\n",
    "##따라서 재현율은 올라가지만 그에 따라 나머지 값들은 작아지게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임계 값:  0.4\n",
      "오차행렬\n",
      "[[99 19]\n",
      " [10 51]]\n",
      "정확도: 0.8380, 정밀도: 0.7286, 재현율: 0.8361\n",
      "\n",
      "\n",
      "임계 값:  0.45\n",
      "오차행렬\n",
      "[[103  15]\n",
      " [ 12  49]]\n",
      "정확도: 0.8492, 정밀도: 0.7656, 재현율: 0.8033\n",
      "\n",
      "\n",
      "임계 값:  0.5\n",
      "오차행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도: 0.8492, 정밀도: 0.7742, 재현율: 0.7869\n",
      "\n",
      "\n",
      "임계 값:  0.55\n",
      "오차행렬\n",
      "[[109   9]\n",
      " [ 15  46]]\n",
      "정확도: 0.8659, 정밀도: 0.8364, 재현율: 0.7541\n",
      "\n",
      "\n",
      "임계 값:  0.6\n",
      "오차행렬\n",
      "[[112   6]\n",
      " [ 16  45]]\n",
      "정확도: 0.8771, 정밀도: 0.8824, 재현율: 0.7377\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##임계값을 0.4~0.6까지 0.05씩 증가하면서 각 결과를 관찰해보겠습니다.\n",
    "\n",
    "thresholds = [0.4,0.45,0.5,0.55,0.6]\n",
    "\n",
    "def get_eval_by_threshold(y_test, pred_proba_c1, thresholds):\n",
    "    for customed_threshold in  thresholds:\n",
    "        binarizer = Binarizer(threshold = customed_threshold).fit(pred_proba_c1)\n",
    "        custom_predict = binarizer.transform(pred_proba_c1)\n",
    "        print('임계 값: ', customed_threshold)\n",
    "        get_clf_eval(y_test, custom_predict)\n",
    "        print('\\n')\n",
    "get_eval_by_threshold(y_test, pred_proba[:,1].reshape(-1,1), thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index:  [  0  15  30  45  60  75  90 105 120 135]\n",
      "임계값:  [0.1  0.12 0.14 0.19 0.28 0.4  0.57 0.67 0.82 0.95]\n",
      "\n",
      "\n",
      "정밀도:  [0.39 0.44 0.47 0.54 0.65 0.73 0.84 0.95 0.96 1.  ]\n",
      "재현율:  [1.   0.97 0.9  0.9  0.9  0.84 0.75 0.61 0.38 0.15]\n"
     ]
    }
   ],
   "source": [
    "##이러한 과정을 간단하게 해주는 함수가 precision_recall_curve함수입니다.\n",
    "##입력으로 실제 클래스값 배열, 예측확률배열을 받고 출력으로 정밀도와 재현율, 임계값을 반환합니다.\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "pred_proba_class1 = lr_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_class1)\n",
    "\n",
    "##이때 thresholds는 임계값들의 배열이므로, 특정 인덱스만을 뽑아서 따로 사용합니다.\n",
    "thr_index = np.arange(0, thresholds.shape[0], 15)\n",
    "print(\"index: \", thr_index)\n",
    "print(\"임계값: \", np.round(thresholds[thr_index], 2))\n",
    "print('\\n')\n",
    "print(\"정밀도: \", np.round(precisions[thr_index],2))\n",
    "print(\"재현율: \", np.round(recalls[thr_index], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##위 결과를 그래프로 나타내면 다음과 같습니다.\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "def precision_recall_curve_plot(y_test, pred_proba_c1):\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_c1)\n",
    "    \n",
    "    plt.figure(figsize=(8,6))\n",
    "    threshold_boundry = thresholds.shape[0]\n",
    "    plt.plot(thresholds, precisions[0:threshold_boundry], linestyle = \"--\", label = \"precision\")\n",
    "    plt.plot(thresholds, recalls[0:threshold_boundry], label = \"recall\")\n",
    "    \n",
    "    stat, end = plt.xlim()\n",
    "    plt.xticks(np.round(np.arange(start, end, 0.1), 2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
